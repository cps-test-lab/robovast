{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c13db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robovast.common.analysis import read_output_files, read_output_csv, get_behavior_info\n",
    "import pandas as pd\n",
    "from robovast_nav.gui import MapVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "DATA_DIR = ''\n",
    "\n",
    "df = read_output_files(DATA_DIR, lambda test_dir: read_output_csv(test_dir, \"poses.csv\"))\n",
    "\n",
    "# Error checking: Ensure we have data\n",
    "if df.empty:\n",
    "    raise ValueError(\"No pose data found. Please check DATA_DIR path and ensure pose files exist.\")\n",
    "\n",
    "# Generate colors for each test\n",
    "tests = df['test'].unique()\n",
    "if len(tests) == 0:\n",
    "    raise ValueError(\"No test data found in the dataframe.\")\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(tests)))\n",
    "\n",
    "df.loc[df['frame'] == 'turtlebot4_base_link_gt', 'position.x'] += 8\n",
    "\n",
    "df_behaviors = read_output_files(DATA_DIR, lambda test_dir: read_output_csv(test_dir, \"behaviors.csv\"))\n",
    "if df_behaviors.empty:\n",
    "    raise ValueError(\"No behavior data found. Please check DATA_DIR path and ensure behavior files exist.\")\n",
    "\n",
    "df_behavior_info = get_behavior_info('differential_drive_robot.nav_to_pose', df_behaviors)\n",
    "if df_behavior_info.empty:\n",
    "    raise ValueError(\"No behavior info extracted. Check if 'differential_drive_robot.nav_to_pose' behavior exists in the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cacf4f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85758911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Run Comparison: All Robot Paths Ground Truth\n",
    "\n",
    "# Create single visualization with all robot paths ground truth\n",
    "viz = MapVisualizer()\n",
    "viz.load_map(\"/opt/ros/jazzy/share/nav2_bringup/maps/depot.yaml\")\n",
    "viz.create_figure(figsize=(14, 12))\n",
    "\n",
    "# Draw all robot paths\n",
    "for test, color in zip(tests, colors):\n",
    "    df_test = df[df['test'] == test]\n",
    "    df_gt_mask = df_test['frame'] == 'turtlebot4_base_link_gt'\n",
    "    path_robot = list(zip(df_test.loc[df_gt_mask, 'position.x'], df_test.loc[df_gt_mask, 'position.y']))\n",
    "    viz.draw_path(path_robot, color=color, linewidth=1.5, label=f'Run {test}', show_endpoints=False)\n",
    "\n",
    "viz.ax.set_title(f'Multi-Run Comparison: All {len(tests)} Robot Paths', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "viz.ax.legend(loc='upper left', fontsize=9, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703eb0f",
   "metadata": {},
   "source": [
    "## Navigation Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze navigation duration across all runs\n",
    "# print(\"Navigation Duration Statistics:\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Display the behavior info dataframe\n",
    "# print(f\"\\nTotal runs analyzed: {len(df_behavior_info)}\")\n",
    "# print(f\"\\nDuration statistics:\")\n",
    "# print(f\"  Mean: {df_behavior_info['duration'].mean():.2f} seconds\")\n",
    "# print(f\"  Std Dev: {df_behavior_info['duration'].std():.2f} seconds\")\n",
    "# print(f\"  Median: {df_behavior_info['duration'].median():.2f} seconds\")\n",
    "# print(f\"  Min: {df_behavior_info['duration'].min():.2f} seconds\")\n",
    "# print(f\"  Max: {df_behavior_info['duration'].max():.2f} seconds\")\n",
    "# print(f\"  Range: {df_behavior_info['duration'].max() - df_behavior_info['duration'].min():.2f} seconds\")\n",
    "# print(f\"  Coefficient of Variation: {(df_behavior_info['duration'].std()/df_behavior_info['duration'].mean())*100:.2f}%\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"\\nDetailed Duration by Run:\")\n",
    "# df_behavior_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigation Duration Comparison - Crisp Visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Prepare data\n",
    "durations = df_behavior_info['duration'].values\n",
    "tests_behavior = df_behavior_info['test'].values\n",
    "x_pos = np.arange(len(durations))\n",
    "\n",
    "# 1. Bar Chart - Duration by Run\n",
    "ax = axes[0, 0]\n",
    "bars = ax.bar(x_pos, durations, alpha=0.75, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Run Number', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Duration (seconds)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Navigation Duration by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests_behavior])\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, duration in enumerate(durations):\n",
    "    ax.text(i, duration + 0.5, f'{duration:.1f}s', ha='center', va='bottom', \n",
    "            fontsize=9, fontweight='bold')\n",
    "\n",
    "# Add mean line\n",
    "mean_duration = durations.mean()\n",
    "ax.axhline(mean_duration, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {mean_duration:.1f}s', alpha=0.7)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# 2. Box Plot - Duration Distribution\n",
    "ax = axes[0, 1]\n",
    "bp = ax.boxplot([durations], widths=0.5, patch_artist=True, \n",
    "                tick_labels=['All Runs'], showmeans=True)\n",
    "bp['boxes'][0].set_facecolor('steelblue')\n",
    "bp['boxes'][0].set_alpha(0.7)\n",
    "bp['boxes'][0].set_edgecolor('black')\n",
    "bp['boxes'][0].set_linewidth(2)\n",
    "\n",
    "for element in ['whiskers', 'fliers', 'medians', 'caps']:\n",
    "    plt.setp(bp[element], color='black', linewidth=2)\n",
    "plt.setp(bp['means'], marker='D', markerfacecolor='red', markeredgecolor='black', markersize=8)\n",
    "\n",
    "ax.set_ylabel('Duration (seconds)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Navigation Duration Distribution', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# Add statistics annotations\n",
    "q1, median, q3 = np.percentile(durations, [25, 50, 75])\n",
    "ax.text(1.3, q1, f'Q1: {q1:.1f}s', fontsize=9, va='center')\n",
    "ax.text(1.3, median, f'Median: {median:.1f}s', fontsize=9, va='center', fontweight='bold')\n",
    "ax.text(1.3, q3, f'Q3: {q3:.1f}s', fontsize=9, va='center')\n",
    "ax.text(1.3, mean_duration, f'Mean: {mean_duration:.1f}s', fontsize=9, va='center', color='red')\n",
    "\n",
    "# 3. Histogram - Duration Distribution\n",
    "ax = axes[0, 2]\n",
    "n, bins, patches = ax.hist(durations, bins=15, color='steelblue', alpha=0.7, \n",
    "                           edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Color bars based on value\n",
    "for i, patch in enumerate(patches):\n",
    "    patch.set_facecolor(colors[i % len(colors)])\n",
    "\n",
    "ax.axvline(mean_duration, color='red', linestyle='--', linewidth=2.5, \n",
    "           label=f'Mean: {mean_duration:.1f}s', alpha=0.8)\n",
    "ax.axvline(median, color='green', linestyle='--', linewidth=2.5, \n",
    "           label=f'Median: {median:.1f}s', alpha=0.8)\n",
    "ax.set_xlabel('Duration (seconds)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Duration Distribution', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# 4. Sorted Duration Plot\n",
    "ax = axes[1, 0]\n",
    "sorted_indices = np.argsort(durations)\n",
    "sorted_durations = durations[sorted_indices]\n",
    "sorted_tests = tests_behavior[sorted_indices]\n",
    "\n",
    "bars = ax.bar(range(len(sorted_durations)), sorted_durations, alpha=0.75, \n",
    "              color=[colors[i] for i in sorted_indices], edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Sorted Run Index', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Duration (seconds)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Navigation Duration (Sorted)', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# Add labels for best and worst\n",
    "ax.text(0, sorted_durations[0] + 0.5, f'Best: {sorted_durations[0]:.1f}s\\n(Run {sorted_tests[0]})', \n",
    "        ha='center', va='bottom', fontsize=9, fontweight='bold', color='green')\n",
    "ax.text(len(sorted_durations)-1, sorted_durations[-1] + 0.5, \n",
    "        f'Worst: {sorted_durations[-1]:.1f}s\\n(Run {sorted_tests[-1]})', \n",
    "        ha='center', va='bottom', fontsize=9, fontweight='bold', color='red')\n",
    "\n",
    "# 5. Cumulative Distribution\n",
    "ax = axes[1, 1]\n",
    "sorted_durations_cdf = np.sort(durations)\n",
    "cumulative = np.arange(1, len(sorted_durations_cdf) + 1) * (100.0 / len(sorted_durations_cdf))\n",
    "\n",
    "ax.plot(sorted_durations_cdf, cumulative, color='steelblue', linewidth=3, marker='o', \n",
    "        markersize=8, markerfacecolor='white', markeredgecolor='steelblue', markeredgewidth=2)\n",
    "ax.set_xlabel('Duration (seconds)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Cumulative Percentage (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Cumulative Distribution of Duration', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "# Add reference lines\n",
    "for percentile in [25, 50, 75]:\n",
    "    value = np.percentile(durations, percentile)\n",
    "    ax.axhline(percentile, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    ax.axvline(value, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    ax.text(value, percentile + 2, f'{percentile}%: {value:.1f}s', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 6. Deviation from Mean\n",
    "ax = axes[1, 2]\n",
    "deviations = durations - mean_duration\n",
    "colors_dev = ['green' if d <= 0 else 'red' for d in deviations]\n",
    "\n",
    "bars = ax.bar(x_pos, deviations, alpha=0.75, color=colors_dev, edgecolor='black', linewidth=1.5)\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "ax.set_xlabel('Run Number', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Deviation from Mean (seconds)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Duration Deviation from Mean', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests_behavior])\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, dev in enumerate(deviations):\n",
    "    va = 'bottom' if dev > 0 else 'top'\n",
    "    offset = 0.2 if dev > 0 else -0.2\n",
    "    ax.text(i, dev + offset, f'{dev:+.1f}s', ha='center', va=va, \n",
    "            fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for multi-run comparison\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split by frame and prepare for all runs\n",
    "df_robot = df[df['frame'] == 'base_link'].copy()\n",
    "df_groundtruth = df[df['frame'] == 'turtlebot4_base_link_gt'].copy()\n",
    "\n",
    "# Error check: Ensure we have robot and ground truth data\n",
    "if df_robot.empty:\n",
    "    raise ValueError(\"No robot data (frame='base_link') found. Cannot perform error analysis.\")\n",
    "\n",
    "if df_groundtruth.empty:\n",
    "    raise ValueError(\"No ground truth data (frame='turtlebot4_base_link_gt') found. Cannot perform error analysis.\")\n",
    "\n",
    "# Sort by test and timestamp\n",
    "df_robot.sort_values(['test', 'timestamp'], inplace=True)\n",
    "df_groundtruth.sort_values(['test', 'timestamp'], inplace=True)\n",
    "\n",
    "# print(f\"Processing {len(tests)} runs for comparison\")\n",
    "# print(f\"Robot data points: {len(df_robot)}\")\n",
    "# print(f\"Ground truth data points: {len(df_groundtruth)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3709985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate errors for each run separately\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Store results for each run\n",
    "run_errors = {}\n",
    "run_stats = []\n",
    "\n",
    "for test in tests:\n",
    "    # Get data for this specific run\n",
    "    df_robot_test = df_robot[df_robot['test'] == test].copy()\n",
    "    df_gt_test = df_groundtruth[df_groundtruth['test'] == test].copy()\n",
    "    \n",
    "    # Error checking: Ensure we have data for this test\n",
    "    if df_robot_test.empty or df_gt_test.empty:\n",
    "        print(f\"Warning: Skipping test {test} - no robot or ground truth data found\")\n",
    "        continue\n",
    "    \n",
    "    if len(df_robot_test) < 2 or len(df_gt_test) < 2:\n",
    "        print(f\"Warning: Skipping test {test} - insufficient data points (need at least 2)\")\n",
    "        continue\n",
    "    \n",
    "    # Find common time range\n",
    "    time_start = max(df_robot_test['timestamp'].iloc[0], df_gt_test['timestamp'].iloc[0])\n",
    "    time_end = min(df_robot_test['timestamp'].iloc[-1], df_gt_test['timestamp'].iloc[-1])\n",
    "    \n",
    "    if time_start >= time_end:\n",
    "        print(f\"Warning: Skipping test {test} - no overlapping time range\")\n",
    "        continue\n",
    "    \n",
    "    # Create interpolation functions for ground truth\n",
    "    gt_timestamps = df_gt_test['timestamp'].values\n",
    "    gt_interp_x = interp1d(gt_timestamps, df_gt_test['position.x'].values, kind='linear', fill_value='extrapolate')\n",
    "    gt_interp_y = interp1d(gt_timestamps, df_gt_test['position.y'].values, kind='linear', fill_value='extrapolate')\n",
    "    gt_interp_yaw = interp1d(gt_timestamps, df_gt_test['orientation.yaw'].values, kind='linear', fill_value='extrapolate')\n",
    "    \n",
    "    # Filter robot data to common time range\n",
    "    time_mask = (df_robot_test['timestamp'] >= time_start) & (df_robot_test['timestamp'] <= time_end)\n",
    "    df_robot_aligned = df_robot_test[time_mask].copy()\n",
    "    \n",
    "    if df_robot_aligned.empty:\n",
    "        print(f\"Warning: Skipping test {test} - no data in common time range\")\n",
    "        continue\n",
    "    \n",
    "    robot_timestamps = df_robot_aligned['timestamp'].values\n",
    "    \n",
    "    # Interpolate ground truth at robot timestamps\n",
    "    gt_x = gt_interp_x(robot_timestamps)\n",
    "    gt_y = gt_interp_y(robot_timestamps)\n",
    "    gt_yaw = gt_interp_yaw(robot_timestamps)\n",
    "    \n",
    "    # Calculate position errors\n",
    "    position_error_x = df_robot_aligned['position.x'].values - gt_x\n",
    "    position_error_y = df_robot_aligned['position.y'].values - gt_y\n",
    "    absolute_position_error = np.sqrt(position_error_x**2 + position_error_y**2)\n",
    "    \n",
    "    # Calculate orientation error\n",
    "    orientation_error = df_robot_aligned['orientation.yaw'].values - gt_yaw\n",
    "    orientation_error = np.arctan2(np.sin(orientation_error), np.cos(orientation_error))\n",
    "    \n",
    "    # Store errors for this run\n",
    "    run_errors[test] = {\n",
    "        'timestamps': robot_timestamps,\n",
    "        'position_error': absolute_position_error,\n",
    "        'position_error_x': position_error_x,\n",
    "        'position_error_y': position_error_y,\n",
    "        'orientation_error': orientation_error\n",
    "    }\n",
    "    \n",
    "    # Calculate statistics\n",
    "    run_stats.append({\n",
    "        'test': test,\n",
    "        'mean_pos_error': np.mean(absolute_position_error),\n",
    "        'std_pos_error': np.std(absolute_position_error),\n",
    "        'max_pos_error': np.max(absolute_position_error),\n",
    "        'median_pos_error': np.median(absolute_position_error),\n",
    "        'p95_pos_error': np.percentile(absolute_position_error, 95),\n",
    "        'mean_orient_error': np.mean(np.abs(orientation_error)),\n",
    "        'std_orient_error': np.std(orientation_error),\n",
    "        'max_orient_error': np.max(np.abs(orientation_error))\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easy analysis\n",
    "if len(run_stats) == 0:\n",
    "    raise ValueError(\"No valid test data found after error calculation. Check that robot and ground truth data exist for at least one test.\")\n",
    "\n",
    "stats_df = pd.DataFrame(run_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robovast.common.analysis import calculate_speeds_from_poses\n",
    "\n",
    "# Error check: Ensure we have ground truth data before calculating speeds\n",
    "if df_groundtruth.empty:\n",
    "    raise ValueError(\"Cannot calculate speeds - ground truth dataframe is empty\")\n",
    "\n",
    "df_gt_speeds = calculate_speeds_from_poses(df_groundtruth)\n",
    "\n",
    "# Error check: Ensure speed calculation succeeded\n",
    "if df_gt_speeds.empty:\n",
    "    raise ValueError(\"Speed calculation returned empty dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59756c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Speed Statistics by Run\n",
    "# print(\"Speed Statistics by Test Run:\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "speed_stats = []\n",
    "for test in tests:\n",
    "    df_test_speeds = df_gt_speeds[df_gt_speeds['test'] == test]\n",
    "    \n",
    "    linear_speeds = df_test_speeds['linear_speed'].values\n",
    "    angular_speeds = df_test_speeds['angular_speed'].values\n",
    "    \n",
    "    speed_stats.append({\n",
    "        'test': test,\n",
    "        'mean_linear': np.mean(linear_speeds),\n",
    "        'max_linear': np.max(linear_speeds),\n",
    "        'std_linear': np.std(linear_speeds),\n",
    "        'median_linear': np.median(linear_speeds),\n",
    "        'mean_angular': np.mean(np.abs(angular_speeds)),\n",
    "        'max_angular': np.max(np.abs(angular_speeds)),\n",
    "        'std_angular': np.std(angular_speeds),\n",
    "        'median_angular': np.median(np.abs(angular_speeds))\n",
    "    })\n",
    "\n",
    "speed_stats_df = pd.DataFrame(speed_stats)\n",
    "# print(speed_stats_df)\n",
    "# print(\"\\nOverall Statistics:\")\n",
    "# print(f\"Mean Linear Speed (avg): {speed_stats_df['mean_linear'].mean():.3f} m/s (±{speed_stats_df['mean_linear'].std():.3f})\")\n",
    "# print(f\"Mean Angular Speed (avg): {speed_stats_df['mean_angular'].mean():.3f} rad/s (±{speed_stats_df['mean_angular'].std():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration vs Performance Metrics Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Duration vs Mean Position Error\n",
    "ax = axes[0]\n",
    "durations_for_scatter = df_behavior_info['duration'].values\n",
    "mean_pos_errors = stats_df['mean_pos_error'].values\n",
    "\n",
    "# Error check: Ensure we have data to plot\n",
    "if len(durations_for_scatter) == 0 or len(mean_pos_errors) == 0:\n",
    "    print(\"Warning: No data available for duration vs performance comparison\")\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    scatter = ax.scatter(durations_for_scatter, mean_pos_errors, c=colors, s=250, \n",
    "                        alpha=0.75, edgecolors='black', linewidth=2)\n",
    "\n",
    "    # Add labels for each point\n",
    "    for i, test in enumerate(tests):\n",
    "        ax.annotate(f'Run {test}', (durations_for_scatter[i], mean_pos_errors[i]),\n",
    "                   xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
    "\n",
    "    # Add trend line\n",
    "    z = np.polyfit(durations_for_scatter, mean_pos_errors, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(durations_for_scatter, p(durations_for_scatter), \"r--\", alpha=0.8, linewidth=2,\n",
    "            label=f'Trend: y={z[0]:.4f}x+{z[1]:.4f}')\n",
    "\n",
    "    ax.set_xlabel('Navigation Duration (seconds)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Mean Position Error (m)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Duration vs Position Error', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(durations_for_scatter, mean_pos_errors)[0, 1]\n",
    "    ax.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "            transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7), verticalalignment='top')\n",
    "\n",
    "    # 2. Duration vs Mean Linear Speed\n",
    "    ax = axes[1]\n",
    "    mean_linear_speeds = speed_stats_df['mean_linear'].values\n",
    "\n",
    "    scatter = ax.scatter(durations_for_scatter, mean_linear_speeds, c=colors, s=250, \n",
    "                        alpha=0.75, edgecolors='black', linewidth=2)\n",
    "\n",
    "    # Add labels\n",
    "    for i, test in enumerate(tests):\n",
    "        ax.annotate(f'Run {test}', (durations_for_scatter[i], mean_linear_speeds[i]),\n",
    "                   xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
    "\n",
    "    # Add trend line\n",
    "    z = np.polyfit(durations_for_scatter, mean_linear_speeds, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(durations_for_scatter, p(durations_for_scatter), \"r--\", alpha=0.8, linewidth=2,\n",
    "            label=f'Trend: y={z[0]:.4f}x+{z[1]:.4f}')\n",
    "\n",
    "    ax.set_xlabel('Navigation Duration (seconds)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Mean Linear Speed (m/s)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Duration vs Mean Speed', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(durations_for_scatter, mean_linear_speeds)[0, 1]\n",
    "    ax.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "            transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7), verticalalignment='top')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary - add error checks for array access\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DURATION ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nNavigation Duration:\")\n",
    "    print(f\"  Mean: {mean_duration:.2f} seconds\")\n",
    "    print(f\"  Std Dev: {durations.std():.2f} seconds\")\n",
    "    print(f\"  Range: {durations.min():.2f}s - {durations.max():.2f}s ({durations.max() - durations.min():.2f}s difference)\")\n",
    "    print(f\"  Coefficient of Variation: {(durations.std()/mean_duration)*100:.2f}%\")\n",
    "    \n",
    "    # Add safety checks for sorted array access\n",
    "    if len(sorted_tests) > 0 and len(sorted_durations) > 0:\n",
    "        print(f\"\\nBest Run: {sorted_tests[0]} with {sorted_durations[0]:.2f} seconds\")\n",
    "        print(f\"Worst Run: {sorted_tests[-1]} with {sorted_durations[-1]:.2f} seconds\")\n",
    "        print(f\"Performance Difference: {((sorted_durations[-1] - sorted_durations[0]) / sorted_durations[0] * 100):.1f}%\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d2a91",
   "metadata": {},
   "source": [
    "## Localization Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Run Comparison: Position Error Over Time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Error check: Ensure we have error data\n",
    "if len(run_errors) == 0:\n",
    "    print(\"Warning: No error data available for plotting\")\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    # 1. Position errors over time for all runs\n",
    "    ax = axes[0, 0]\n",
    "    for test, color in zip(tests, colors):\n",
    "        if test not in run_errors:\n",
    "            continue\n",
    "        errors = run_errors[test]\n",
    "        if len(errors['timestamps']) == 0:\n",
    "            continue\n",
    "        # Normalize time to start at 0\n",
    "        time_normalized = errors['timestamps'] - errors['timestamps'][0]\n",
    "        ax.plot(time_normalized, errors['position_error'], color=color, alpha=0.6, linewidth=1.5, label=f'Run {test}')\n",
    "\n",
    "    ax.set_xlabel('Time (s)', fontsize=11)\n",
    "    ax.set_ylabel('Absolute Position Error (m)', fontsize=11)\n",
    "    ax.set_title('Position Error Over Time - All Runs', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=8, ncol=2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Mean error trajectory with standard deviation band\n",
    "    ax = axes[0, 1]\n",
    "    # Find common time length (use shortest run)\n",
    "    if len(run_errors) > 0:\n",
    "        min_length = min(len(run_errors[test]['position_error']) for test in run_errors.keys())\n",
    "\n",
    "        if min_length > 1:\n",
    "            # Interpolate all runs to common time grid\n",
    "            common_time = np.linspace(0, 100, min_length)  # Normalized to 100 seconds\n",
    "            error_matrix = []\n",
    "\n",
    "            for test in tests:\n",
    "                if test not in run_errors:\n",
    "                    continue\n",
    "                errors = run_errors[test]\n",
    "                if len(errors['position_error']) < 2:\n",
    "                    continue\n",
    "                time_normalized = np.linspace(0, 100, len(errors['position_error']))\n",
    "                interp_func = interp1d(time_normalized, errors['position_error'], kind='linear')\n",
    "                error_matrix.append(interp_func(common_time))\n",
    "\n",
    "            if len(error_matrix) > 0:\n",
    "                error_matrix = np.array(error_matrix)\n",
    "                mean_error = np.mean(error_matrix, axis=0)\n",
    "                std_error = np.std(error_matrix, axis=0)\n",
    "\n",
    "                ax.plot(common_time, mean_error, 'b-', linewidth=2.5, label='Mean')\n",
    "                ax.fill_between(common_time, mean_error - std_error, mean_error + std_error, \n",
    "                                alpha=0.3, color='blue', label='±1 Std Dev')\n",
    "\n",
    "    ax.set_xlabel('Normalized Time (s)', fontsize=11)\n",
    "    ax.set_ylabel('Absolute Position Error (m)', fontsize=11)\n",
    "    ax.set_title('Mean Position Error with Variability Band', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3. Orientation errors over time for all runs\n",
    "    ax = axes[1, 0]\n",
    "    for test, color in zip(tests, colors):\n",
    "        if test not in run_errors:\n",
    "            continue\n",
    "        errors = run_errors[test]\n",
    "        if len(errors['timestamps']) == 0:\n",
    "            continue\n",
    "        time_normalized = errors['timestamps'] - errors['timestamps'][0]\n",
    "        ax.plot(time_normalized, np.abs(errors['orientation_error']), color=color, alpha=0.6, linewidth=1.5, label=f'Run {test}')\n",
    "\n",
    "    ax.set_xlabel('Time (s)', fontsize=11)\n",
    "    ax.set_ylabel('Absolute Orientation Error (rad)', fontsize=11)\n",
    "    ax.set_title('Orientation Error Over Time - All Runs', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=8, ncol=2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4. Box plot comparison of position errors across runs\n",
    "    ax = axes[1, 1]\n",
    "    error_data = [run_errors[test]['position_error'] for test in tests if test in run_errors and len(run_errors[test]['position_error']) > 0]\n",
    "    \n",
    "    if len(error_data) > 0:\n",
    "        bp = ax.boxplot(error_data, tick_labels=[f'{t}' for t in tests if t in run_errors and len(run_errors[t]['position_error']) > 0], patch_artist=True)\n",
    "\n",
    "        # Color boxes - only for tests with data\n",
    "        valid_colors = [colors[i] for i, test in enumerate(tests) if test in run_errors and len(run_errors[test]['position_error']) > 0]\n",
    "        for patch, color in zip(bp['boxes'], valid_colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.6)\n",
    "\n",
    "    ax.set_xlabel('Run Number', fontsize=11)\n",
    "    ax.set_ylabel('Absolute Position Error (m)', fontsize=11)\n",
    "    ax.set_title('Position Error Distribution Across Runs', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e20ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Comparison Across Runs\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Bar chart of mean errors with error bars (std dev)\n",
    "ax = axes[0, 0]\n",
    "x_pos = np.arange(len(tests))\n",
    "means = stats_df['mean_pos_error'].values\n",
    "stds = stats_df['std_pos_error'].values\n",
    "\n",
    "bars = ax.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Mean Position Error (m)', fontsize=11)\n",
    "ax.set_title('Mean Position Error by Run (with Std Dev)', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    ax.text(i, mean + std + 0.01, f'{mean:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. Max error comparison\n",
    "ax = axes[0, 1]\n",
    "maxs = stats_df['max_pos_error'].values\n",
    "bars = ax.bar(x_pos, maxs, alpha=0.7, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Max Position Error (m)', fontsize=11)\n",
    "ax.set_title('Maximum Position Error by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Mean orientation error comparison\n",
    "ax = axes[1, 0]\n",
    "orient_means = stats_df['mean_orient_error'].values\n",
    "orient_stds = stats_df['std_orient_error'].values\n",
    "\n",
    "bars = ax.bar(x_pos, orient_means, yerr=orient_stds, capsize=5, alpha=0.7, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Mean Orientation Error (rad)', fontsize=11)\n",
    "ax.set_title('Mean Orientation Error by Run (with Std Dev)', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Percentile comparison (50th, 95th)\n",
    "ax = axes[1, 1]\n",
    "p50s = stats_df['median_pos_error'].values\n",
    "p95s = stats_df['p95_pos_error'].values\n",
    "\n",
    "width = 0.35\n",
    "x_pos1 = x_pos - width/2\n",
    "x_pos2 = x_pos + width/2\n",
    "\n",
    "ax.bar(x_pos1, p50s, width, label='Median (50th)', alpha=0.7, color='skyblue', edgecolor='black', linewidth=1.5)\n",
    "ax.bar(x_pos2, p95s, width, label='95th Percentile', alpha=0.7, color='coral', edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Position Error (m)', fontsize=11)\n",
    "ax.set_title('Position Error Percentiles by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce44313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Distribution Comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Overlayed histograms of position errors\n",
    "ax = axes[0, 0]\n",
    "for test, color in zip(tests, colors):\n",
    "    errors = run_errors[test]['position_error']\n",
    "    ax.hist(errors, bins=40, alpha=0.5, color=color, label=f'Run {test}', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Absolute Position Error (m)', fontsize=11)\n",
    "ax.set_ylabel('Frequency', fontsize=11)\n",
    "ax.set_title('Position Error Distribution - All Runs Overlayed', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Cumulative distribution functions for all runs\n",
    "ax = axes[0, 1]\n",
    "for test, color in zip(tests, colors):\n",
    "    errors = run_errors[test]['position_error']\n",
    "    sorted_errors = np.sort(errors)\n",
    "    cumulative = np.arange(1, len(sorted_errors) + 1) * (100.0 / len(sorted_errors))\n",
    "    ax.plot(sorted_errors, cumulative, color=color, linewidth=2, alpha=0.7, label=f'Run {test}')\n",
    "\n",
    "ax.set_xlabel('Absolute Position Error (m)', fontsize=11)\n",
    "ax.set_ylabel('Cumulative Percentage (%)', fontsize=11)\n",
    "ax.set_title('Cumulative Distribution of Position Errors', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add reference lines for key percentiles\n",
    "ax.axhline(50, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.axhline(95, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.text(ax.get_xlim()[1]*0.95, 50, '50%', ha='right', va='bottom', fontsize=9)\n",
    "ax.text(ax.get_xlim()[1]*0.95, 95, '95%', ha='right', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Violin plots showing distribution shape\n",
    "ax = axes[1, 0]\n",
    "error_data = [run_errors[test]['position_error'] for test in tests]\n",
    "parts = ax.violinplot(error_data, positions=range(len(tests)), showmeans=True, showmedians=True)\n",
    "\n",
    "# Color the violin plots\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(colors[i])\n",
    "    pc.set_alpha(0.6)\n",
    "\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Absolute Position Error (m)', fontsize=11)\n",
    "ax.set_title('Position Error Distribution Shape by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(range(len(tests)))\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Orientation error distributions (overlayed histograms)\n",
    "ax = axes[1, 1]\n",
    "for test, color in zip(tests, colors):\n",
    "    errors = np.abs(run_errors[test]['orientation_error'])\n",
    "    ax.hist(errors, bins=40, alpha=0.5, color=color, label=f'Run {test}', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Absolute Orientation Error (rad)', fontsize=11)\n",
    "ax.set_ylabel('Frequency', fontsize=11)\n",
    "ax.set_title('Orientation Error Distribution - All Runs Overlayed', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Statistics and Summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Summary statistics table visualization\n",
    "ax = axes[0, 0]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Calculate overall statistics\n",
    "overall_mean = stats_df['mean_pos_error'].mean()\n",
    "overall_std = stats_df['mean_pos_error'].std()\n",
    "overall_min = stats_df['mean_pos_error'].min()\n",
    "overall_max = stats_df['mean_pos_error'].max()\n",
    "\n",
    "table_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['Overall Mean Pos Error', f'{overall_mean:.4f} m'],\n",
    "    ['Std Dev Across Runs', f'{overall_std:.4f} m'],\n",
    "    ['Best Run Mean Error', f'{overall_min:.4f} m'],\n",
    "    ['Worst Run Mean Error', f'{overall_max:.4f} m'],\n",
    "    ['Coefficient of Variation', f'{(overall_std/overall_mean)*100:.2f}%'],\n",
    "    ['', ''],\n",
    "    ['Mean Orient Error (avg)', f'{stats_df[\"mean_orient_error\"].mean():.4f} rad ({np.degrees(stats_df[\"mean_orient_error\"].mean()):.2f}°)'],\n",
    "    ['Orient Error Std Dev', f'{stats_df[\"mean_orient_error\"].std():.4f} rad ({np.degrees(stats_df[\"mean_orient_error\"].std()):.2f}°)'],\n",
    "]\n",
    "\n",
    "table = ax.table(cellText=table_data, cellLoc='left', loc='center',\n",
    "                colWidths=[0.5, 0.5])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Style header row\n",
    "for i in range(2):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "ax.set_title('Overall Statistics Across All Runs', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "# 2. Scatter plot: Mean vs Std Dev for each run\n",
    "ax = axes[0, 1]\n",
    "scatter = ax.scatter(stats_df['mean_pos_error'], stats_df['std_pos_error'], \n",
    "                    c=colors, s=200, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "\n",
    "for i, test in enumerate(tests):\n",
    "    ax.annotate(f'Run {test}', \n",
    "               (stats_df.iloc[i]['mean_pos_error'], stats_df.iloc[i]['std_pos_error']),\n",
    "               xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Mean Position Error (m)', fontsize=11)\n",
    "ax.set_ylabel('Standard Deviation (m)', fontsize=11)\n",
    "ax.set_title('Mean vs Variability by Run', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Run consistency heatmap (correlation between runs)\n",
    "ax = axes[1, 0]\n",
    "\n",
    "# Create correlation matrix between runs (using interpolated errors)\n",
    "correlation_matrix = np.corrcoef(error_matrix)\n",
    "\n",
    "im = ax.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=0, vmax=1)\n",
    "ax.set_xticks(range(len(tests)))\n",
    "ax.set_yticks(range(len(tests)))\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.set_yticklabels([f'{t}' for t in tests])\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Run Number', fontsize=11)\n",
    "ax.set_title('Error Pattern Correlation Between Runs', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Correlation', fontsize=10)\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(tests)):\n",
    "    for j in range(len(tests)):\n",
    "        text = ax.text(j, i, f'{correlation_matrix[i, j]:.2f}',\n",
    "                      ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "# 4. Range and quartile visualization\n",
    "ax = axes[1, 1]\n",
    "\n",
    "# Calculate quartiles for each run\n",
    "quartile_data = []\n",
    "for test in tests:\n",
    "    errors = run_errors[test]['position_error']\n",
    "    q1 = np.percentile(errors, 25)\n",
    "    q2 = np.percentile(errors, 50)\n",
    "    q3 = np.percentile(errors, 75)\n",
    "    min_val = np.min(errors)\n",
    "    max_val = np.max(errors)\n",
    "    quartile_data.append([min_val, q1, q2, q3, max_val])\n",
    "\n",
    "quartile_data = np.array(quartile_data)\n",
    "x_pos = np.arange(len(tests))\n",
    "\n",
    "# Plot ranges\n",
    "for i, (color, data) in enumerate(zip(colors, quartile_data)):\n",
    "    ax.plot([i, i], [data[0], data[4]], color=color, linewidth=2, alpha=0.5)\n",
    "    ax.plot([i, i], [data[1], data[3]], color=color, linewidth=6, alpha=0.8)\n",
    "    ax.scatter(i, data[2], color=color, s=100, zorder=5, edgecolors='black', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Run Number', fontsize=11)\n",
    "ax.set_ylabel('Position Error (m)', fontsize=11)\n",
    "ax.set_title('Error Range and Quartiles by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='gray', linewidth=2, alpha=0.5, label='Min-Max Range'),\n",
    "    Line2D([0], [0], color='gray', linewidth=6, alpha=0.8, label='Q1-Q3 (IQR)'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=8, \n",
    "           markeredgecolor='black', markeredgewidth=2, label='Median')\n",
    "]\n",
    "ax.legend(handles=legend_elements, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPREHENSIVE MULTI-RUN COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNumber of Runs: {len(tests)}\")\n",
    "print(f\"\\nPosition Error Statistics Across All Runs:\")\n",
    "print(f\"  Mean of Means: {overall_mean:.4f} m\")\n",
    "print(f\"  Std Dev of Means: {overall_std:.4f} m\")\n",
    "print(f\"  Coefficient of Variation: {(overall_std/overall_mean)*100:.2f}%\")\n",
    "print(f\"  Best Run: {stats_df.loc[stats_df['mean_pos_error'].idxmin(), 'test']} ({overall_min:.4f} m)\")\n",
    "print(f\"  Worst Run: {stats_df.loc[stats_df['mean_pos_error'].idxmax(), 'test']} ({overall_max:.4f} m)\")\n",
    "print(f\"  Range: {overall_max - overall_min:.4f} m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3750bb",
   "metadata": {},
   "source": [
    "## Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebcd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Run Speed Comparison - Crisp Visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Linear Speed Distribution Comparison\n",
    "ax = axes[0, 0]\n",
    "for test, color in zip(tests, colors):\n",
    "    df_test_speeds = df_gt_speeds[df_gt_speeds['test'] == test]\n",
    "    ax.hist(df_test_speeds['linear_speed'].values, bins=40, alpha=0.5, \n",
    "            color=color, label=f'Run {test}', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Linear Speed (m/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Linear Speed Distribution - All Runs', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# 2. Angular Speed Distribution Comparison\n",
    "ax = axes[0, 1]\n",
    "for test, color in zip(tests, colors):\n",
    "    df_test_speeds = df_gt_speeds[df_gt_speeds['test'] == test]\n",
    "    ax.hist(df_test_speeds['angular_speed'].values, bins=40, alpha=0.5, \n",
    "            color=color, label=f'Run {test}', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Angular Speed (rad/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Angular Speed Distribution - All Runs', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# 3. Box Plot - Linear Speed Comparison\n",
    "ax = axes[0, 2]\n",
    "linear_speed_data = [df_gt_speeds[df_gt_speeds['test'] == test]['linear_speed'].values \n",
    "                     for test in tests]\n",
    "bp = ax.boxplot(linear_speed_data, tick_labels=[f'{t}' for t in tests], \n",
    "                patch_artist=True, widths=0.6)\n",
    "\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "    patch.set_edgecolor('black')\n",
    "    patch.set_linewidth(1.5)\n",
    "\n",
    "for element in ['whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "    plt.setp(bp[element], color='black', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Run Number', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Linear Speed (m/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Linear Speed Distribution by Run', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# 4. Bar Chart - Mean Linear Speed with Error Bars\n",
    "ax = axes[1, 0]\n",
    "x_pos = np.arange(len(tests))\n",
    "linear_means = speed_stats_df['mean_linear'].values\n",
    "linear_stds = speed_stats_df['std_linear'].values\n",
    "\n",
    "bars = ax.bar(x_pos, linear_means, yerr=linear_stds, capsize=5, \n",
    "              alpha=0.75, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Run Number', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Mean Linear Speed (m/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Mean Linear Speed by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, (mean, std) in enumerate(zip(linear_means, linear_stds)):\n",
    "    ax.text(i, mean + std + 0.01, f'{mean:.3f}', ha='center', va='bottom', \n",
    "            fontsize=8, fontweight='bold')\n",
    "\n",
    "# 5. Bar Chart - Mean Angular Speed with Error Bars\n",
    "ax = axes[1, 1]\n",
    "angular_means = speed_stats_df['mean_angular'].values\n",
    "angular_stds = speed_stats_df['std_angular'].values\n",
    "\n",
    "bars = ax.bar(x_pos, angular_means, yerr=angular_stds, capsize=5, \n",
    "              alpha=0.75, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Run Number', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Mean Angular Speed (rad/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Mean Angular Speed by Run', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'{t}' for t in tests])\n",
    "ax.grid(True, alpha=0.3, axis='y', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, (mean, std) in enumerate(zip(angular_means, angular_stds)):\n",
    "    ax.text(i, mean + std + 0.01, f'{mean:.3f}', ha='center', va='bottom', \n",
    "            fontsize=8, fontweight='bold')\n",
    "\n",
    "# 6. Scatter Plot - Max Speed Comparison\n",
    "ax = axes[1, 2]\n",
    "max_linear = speed_stats_df['max_linear'].values\n",
    "max_angular = speed_stats_df['max_angular'].values\n",
    "\n",
    "scatter = ax.scatter(max_linear, max_angular, c=colors, s=250, alpha=0.75, \n",
    "                    edgecolors='black', linewidth=2)\n",
    "\n",
    "for i, test in enumerate(tests):\n",
    "    ax.annotate(f'Run {test}', (max_linear[i], max_angular[i]),\n",
    "               xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Max Linear Speed (m/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Max Angular Speed (rad/s)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Maximum Speed Comparison', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed Profile Over Time - Multi-Run Comparison\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Error check: Ensure we have speed data\n",
    "if df_gt_speeds.empty:\n",
    "    print(\"Warning: No speed data available for plotting\")\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    # 1. Linear Speed Over Time - All Runs\n",
    "    ax = axes[0]\n",
    "    for test, color in zip(tests, colors):\n",
    "        df_test_speeds = df_gt_speeds[df_gt_speeds['test'] == test]\n",
    "        if df_test_speeds.empty or len(df_test_speeds) == 0:\n",
    "            continue\n",
    "        timestamps = df_test_speeds['timestamp'].values\n",
    "        # Normalize time to start at 0\n",
    "        timestamps_norm = timestamps - timestamps[0]\n",
    "        linear_speeds = df_test_speeds['linear_speed'].values\n",
    "        \n",
    "        ax.plot(timestamps_norm, linear_speeds, color=color, alpha=0.7, \n",
    "                linewidth=1.5, label=f'Run {test}')\n",
    "\n",
    "    ax.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Linear Speed (m/s)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Linear Speed Profile Over Time - All Runs', fontsize=13, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=9, ncol=3)\n",
    "    ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "    ax.set_ylim(bottom=0)\n",
    "\n",
    "    # 2. Angular Speed Over Time - All Runs\n",
    "    ax = axes[1]\n",
    "    for test, color in zip(tests, colors):\n",
    "        df_test_speeds = df_gt_speeds[df_gt_speeds['test'] == test]\n",
    "        if df_test_speeds.empty or len(df_test_speeds) == 0:\n",
    "            continue\n",
    "        timestamps = df_test_speeds['timestamp'].values\n",
    "        timestamps_norm = timestamps - timestamps[0]\n",
    "        angular_speeds = df_test_speeds['angular_speed'].values\n",
    "        \n",
    "        ax.plot(timestamps_norm, angular_speeds, color=color, alpha=0.7, \n",
    "                linewidth=1.5, label=f'Run {test}')\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Angular Speed (rad/s)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Angular Speed Profile Over Time - All Runs', fontsize=13, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=9, ncol=3)\n",
    "    ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robovast-zq8JDN7z-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
